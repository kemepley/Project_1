{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing some necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that allows us to drop rows based on values we think are suspect\n",
    "\n",
    "def drop_anomolous_rows(df, colname, val):\n",
    "    return df[df[colname] != val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to take columns with years (yr_built, yr_renovated) and bin them by decade\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def bin_by_decade(df, colname):\n",
    "    bins = pd.IntervalIndex.from_tuples([(1900, 1909), (1910, 1919), (1920, 1929), (1930, 1939), (1940, 1949), (1950, 1959), (1960, 1969), (1970, 1979), (1980, 1989), (1990, 1999), (2000, 2010), (2010, 2020)])\n",
    "    series = pd.cut(df[colname], bins)\n",
    "    df[colname] = series\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains all of our data cleaning operations\n",
    "\n",
    "def clean():\n",
    "    \n",
    "# Load the data\n",
    "    \n",
    "    house = pd.read_csv('https://raw.githubusercontent.com/learn-co-students/dsc-v2-mod1-final-project-dc-ds-career-042219/master/kc_house_data.csv')\n",
    "    \n",
    "# Get rid of rows\n",
    "    # The row with 33 bedrooms is a suspicious outlier, so we decided to drop it\n",
    "    # The 454 ?s in sqft_basement needed to be remedied. We chose to drop them--454 seemed like too many to impute. \n",
    "\n",
    "    clean_house = drop_anomolous_rows(house, 'bedrooms', 33)\n",
    "    clean_house = drop_anomolous_rows(house, 'sqft_basement', \"?\")\n",
    "    \n",
    "# Bin decades\n",
    "    \n",
    "    clean_house = bin_by_decade(clean_house, 'yr_built')\n",
    "    clean_house = bin_by_decade(clean_house, 'yr_renovated')\n",
    "    \n",
    "    \n",
    "# Get dummies\n",
    "    # Note: Originally, we dropped waterfront because it had a lot of null values. Get dummies gives you the option to create a dummy for nulls or not.\n",
    "    # We did that, without the null column\n",
    "    clean_house = pd.get_dummies(clean_house, columns=(['waterfront', 'view', 'floors', 'bedrooms', 'condition', 'zipcode', 'yr_built', 'yr_renovated']))\n",
    "    \n",
    "# Drop id, date, waterfront\n",
    "\n",
    "    clean_house = clean_house.drop(['id', 'date'], axis=1)\n",
    "    \n",
    "# Convert sqft_basement from object to float\n",
    "\n",
    "    clean_house['sqft_basement'] = clean_house['sqft_basement'].astype(float, inplace=True)\n",
    "\n",
    "# Return clean_house\n",
    "    \n",
    "    return clean_house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "clean_house = clean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>waterfront_0.0</th>\n",
       "      <th>waterfront_1.0</th>\n",
       "      <th>view_0.0</th>\n",
       "      <th>view_1.0</th>\n",
       "      <th>view_2.0</th>\n",
       "      <th>view_3.0</th>\n",
       "      <th>view_4.0</th>\n",
       "      <th>floors_1.0</th>\n",
       "      <th>floors_1.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7639</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8062</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7503</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sqft_lot15  waterfront_0.0  waterfront_1.0  view_0.0  view_1.0  view_2.0  \\\n",
       "0        5650               0               0         1         0         0   \n",
       "1        7639               1               0         1         0         0   \n",
       "2        8062               1               0         1         0         0   \n",
       "3        5000               1               0         1         0         0   \n",
       "4        7503               1               0         1         0         0   \n",
       "\n",
       "   view_3.0  view_4.0  floors_1.0  floors_1.5  \n",
       "0         0         0           1           0  \n",
       "1         0         0           0           0  \n",
       "2         0         0           1           0  \n",
       "3         0         0           1           0  \n",
       "4         0         0           1           0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_house.iloc[:, 10:20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21143 entries, 0 to 21596\n",
      "Columns: 135 entries, price to yr_renovated_(2010, 2020]\n",
      "dtypes: float64(5), int64(6), uint8(124)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "clean_house.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "\n",
    "X = clean_house.drop([\"price\"], axis=1) #predictors\n",
    "y = clean_house[\"price\"] #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229 16914 4229 16914\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=3)\n",
    "print(len(X_test), len(X_train), len(y_test), len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking out various combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = clean_house[['waterfront_1.0']]\n",
    "y2 = clean_house[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.071</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.071</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1609.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 07 May 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:26:00</td>     <th>  Log-Likelihood:    </th> <td>-3.0019e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21143</td>      <th>  AIC:               </th>  <td>6.004e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21141</td>      <th>  BIC:               </th>  <td>6.004e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td> 5.325e+05</td> <td> 2448.474</td> <td>  217.467</td> <td> 0.000</td> <td> 5.28e+05</td> <td> 5.37e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront_1.0</th> <td> 1.199e+06</td> <td> 2.99e+04</td> <td>   40.117</td> <td> 0.000</td> <td> 1.14e+06</td> <td> 1.26e+06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17340.413</td> <th>  Durbin-Watson:     </th>  <td>   1.958</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>897689.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.599</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>34.099</td>   <th>  Cond. No.          </th>  <td>    12.2</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.071\n",
       "Model:                            OLS   Adj. R-squared:                  0.071\n",
       "Method:                 Least Squares   F-statistic:                     1609.\n",
       "Date:                Tue, 07 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        20:26:00   Log-Likelihood:            -3.0019e+05\n",
       "No. Observations:               21143   AIC:                         6.004e+05\n",
       "Df Residuals:                   21141   BIC:                         6.004e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "const           5.325e+05   2448.474    217.467      0.000    5.28e+05    5.37e+05\n",
       "waterfront_1.0  1.199e+06   2.99e+04     40.117      0.000    1.14e+06    1.26e+06\n",
       "==============================================================================\n",
       "Omnibus:                    17340.413   Durbin-Watson:                   1.958\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           897689.905\n",
       "Skew:                           3.599   Prob(JB):                         0.00\n",
       "Kurtosis:                      34.099   Cond. No.                         12.2\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_int2 = sm.add_constant(X2)\n",
    "model = sm.OLS(y2, predictors_int2).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression 1: Manual scaling and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied function from Model Fit Linear Regression Lab\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:1100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  waterfront_1.0                 with p-value 0.0\n",
      "Add  bathrooms                      with p-value 0.0\n",
      "Add  sqft_living                    with p-value 0.0\n",
      "Drop bathrooms                      with p-value 0.611508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:45: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  zipcode_98004                  with p-value 0.0\n",
      "Add  lat                            with p-value 0.0\n",
      "Add  grade                          with p-value 0.0\n",
      "Add  zipcode_98039                  with p-value 6.2004e-297\n",
      "Add  view_0.0                       with p-value 3.39298e-249\n",
      "Add  zipcode_98112                  with p-value 1.18467e-241\n",
      "Add  zipcode_98040                  with p-value 1.67766e-195\n",
      "Add  zipcode_98105                  with p-value 5.57944e-84\n",
      "Add  condition_3                    with p-value 1.02155e-79\n",
      "Add  zipcode_98119                  with p-value 4.35741e-80\n",
      "Add  view_4.0                       with p-value 8.65977e-76\n",
      "Add  zipcode_98199                  with p-value 2.17883e-61\n",
      "Add  zipcode_98109                  with p-value 1.53737e-61\n",
      "Add  zipcode_98102                  with p-value 1.05391e-62\n",
      "Add  zipcode_98033                  with p-value 2.59056e-56\n",
      "Add  zipcode_98103                  with p-value 8.23958e-56\n",
      "Add  zipcode_98115                  with p-value 6.45772e-55\n",
      "Add  zipcode_98122                  with p-value 1.96412e-57\n",
      "Add  zipcode_98117                  with p-value 8.20782e-53\n",
      "Add  zipcode_98006                  with p-value 2.03581e-53\n",
      "Add  zipcode_98116                  with p-value 1.01869e-48\n",
      "Add  zipcode_98107                  with p-value 1.01161e-47\n",
      "Add  zipcode_98144                  with p-value 1.99144e-48\n",
      "Add  sqft_above                     with p-value 4.04047e-41\n",
      "Add  sqft_basement                  with p-value 3.34634e-67\n",
      "Add  floors_2.0                     with p-value 4.49648e-49\n",
      "Add  zipcode_98136                  with p-value 1.27873e-38\n",
      "Add  floors_3.0                     with p-value 1.23755e-39\n",
      "Add  zipcode_98005                  with p-value 8.48907e-33\n",
      "Add  yr_renovated_(2000, 2010]      with p-value 1.81602e-32\n",
      "Add  zipcode_98126                  with p-value 3.48777e-29\n",
      "Add  bedrooms_4                     with p-value 8.04509e-26\n",
      "Add  zipcode_98029                  with p-value 2.18765e-25\n",
      "Add  zipcode_98118                  with p-value 1.00148e-25\n",
      "Add  zipcode_98008                  with p-value 8.45395e-26\n",
      "Add  view_3.0                       with p-value 1.62774e-25\n",
      "Add  condition_5                    with p-value 1.95665e-25\n",
      "Add  zipcode_98027                  with p-value 9.16489e-21\n",
      "Add  zipcode_98052                  with p-value 2.82245e-22\n",
      "Add  bedrooms_2                     with p-value 1.26689e-19\n",
      "Add  zipcode_98007                  with p-value 6.45031e-17\n",
      "Add  bedrooms_5                     with p-value 1.22029e-14\n",
      "Add  zipcode_98019                  with p-value 1.88664e-12\n",
      "Add  zipcode_98028                  with p-value 2.83876e-12\n",
      "Add  bedrooms_1                     with p-value 1.53143e-10\n",
      "Add  bedrooms_3                     with p-value 1.46761e-11\n",
      "Add  bathrooms                      with p-value 7.06872e-11\n",
      "Add  zipcode_98106                  with p-value 2.16888e-10\n",
      "Add  yr_built_(1930, 1939]          with p-value 2.34849e-10\n",
      "Add  yr_built_(1940, 1949]          with p-value 1.92653e-10\n",
      "Add  zipcode_98075                  with p-value 2.00002e-09\n",
      "Add  zipcode_98011                  with p-value 1.26818e-08\n",
      "Add  zipcode_98155                  with p-value 5.20789e-10\n",
      "Add  zipcode_98077                  with p-value 8.93912e-10\n",
      "Add  sqft_lot                       with p-value 3.76568e-09\n",
      "Add  yr_built_(1920, 1929]          with p-value 7.40313e-08\n",
      "Add  yr_built_(2010, 2020]          with p-value 9.04334e-08\n",
      "Add  yr_built_(1910, 1919]          with p-value 1.30175e-07\n",
      "Add  floors_1.5                     with p-value 3.3418e-09\n",
      "Add  zipcode_98072                  with p-value 1.33817e-06\n",
      "Add  zipcode_98014                  with p-value 3.9471e-07\n",
      "Add  zipcode_98133                  with p-value 1.22377e-06\n",
      "Add  zipcode_98022                  with p-value 6.93681e-07\n",
      "Add  zipcode_98010                  with p-value 2.73029e-06\n",
      "Add  yr_built_(1970, 1979]          with p-value 1.0184e-05\n",
      "Add  zipcode_98178                  with p-value 8.46793e-06\n",
      "Add  bedrooms_6                     with p-value 2.26582e-05\n",
      "Add  yr_built_(1900, 1909]          with p-value 2.59704e-05\n",
      "Add  zipcode_98002                  with p-value 6.46648e-05\n",
      "Add  sqft_living15                  with p-value 8.00674e-05\n",
      "Add  yr_renovated_(2010, 2020]      with p-value 0.000155319\n",
      "Add  bedrooms_8                     with p-value 0.00314657\n",
      "Add  zipcode_98058                  with p-value 0.00387883\n",
      "Add  zipcode_98070                  with p-value 0.0030783\n",
      "Add  zipcode_98065                  with p-value 0.00627888\n",
      "Add  yr_built_(1960, 1969]          with p-value 0.00939475\n",
      "resulting features:\n",
      "['waterfront_1.0', 'sqft_living', 'zipcode_98004', 'lat', 'grade', 'zipcode_98039', 'view_0.0', 'zipcode_98112', 'zipcode_98040', 'zipcode_98105', 'condition_3', 'zipcode_98119', 'view_4.0', 'zipcode_98199', 'zipcode_98109', 'zipcode_98102', 'zipcode_98033', 'zipcode_98103', 'zipcode_98115', 'zipcode_98122', 'zipcode_98117', 'zipcode_98006', 'zipcode_98116', 'zipcode_98107', 'zipcode_98144', 'sqft_above', 'sqft_basement', 'floors_2.0', 'zipcode_98136', 'floors_3.0', 'zipcode_98005', 'yr_renovated_(2000, 2010]', 'zipcode_98126', 'bedrooms_4', 'zipcode_98029', 'zipcode_98118', 'zipcode_98008', 'view_3.0', 'condition_5', 'zipcode_98027', 'zipcode_98052', 'bedrooms_2', 'zipcode_98007', 'bedrooms_5', 'zipcode_98019', 'zipcode_98028', 'bedrooms_1', 'bedrooms_3', 'bathrooms', 'zipcode_98106', 'yr_built_(1930, 1939]', 'yr_built_(1940, 1949]', 'zipcode_98075', 'zipcode_98011', 'zipcode_98155', 'zipcode_98077', 'sqft_lot', 'yr_built_(1920, 1929]', 'yr_built_(2010, 2020]', 'yr_built_(1910, 1919]', 'floors_1.5', 'zipcode_98072', 'zipcode_98014', 'zipcode_98133', 'zipcode_98022', 'zipcode_98010', 'yr_built_(1970, 1979]', 'zipcode_98178', 'bedrooms_6', 'yr_built_(1900, 1909]', 'zipcode_98002', 'sqft_living15', 'yr_renovated_(2010, 2020]', 'bedrooms_8', 'zipcode_98058', 'zipcode_98070', 'zipcode_98065', 'yr_built_(1960, 1969]']\n"
     ]
    }
   ],
   "source": [
    "target = clean_house[\"price\"]\n",
    "predictors = clean_house.drop([\"price\"], axis=1)\n",
    "\n",
    "result = stepwise_selection(predictors, target, verbose = True)\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.812</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.811</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1180.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 07 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:01:06</td>     <th>  Log-Likelihood:    </th> <td> -12341.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21143</td>      <th>  AIC:               </th> <td>2.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21065</td>      <th>  BIC:               </th> <td>2.546e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    77</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                     <td>-1.172e-14</td> <td>    0.003</td> <td>-3.92e-12</td> <td> 1.000</td> <td>   -0.006</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront_1.0</th>            <td>    0.1332</td> <td>    0.004</td> <td>   36.163</td> <td> 0.000</td> <td>    0.126</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living</th>               <td>    0.2455</td> <td>    0.004</td> <td>   69.193</td> <td> 0.000</td> <td>    0.239</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98004</th>             <td>    0.2056</td> <td>    0.003</td> <td>   65.660</td> <td> 0.000</td> <td>    0.200</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lat</th>                       <td>    0.2086</td> <td>    0.005</td> <td>   44.311</td> <td> 0.000</td> <td>    0.199</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade</th>                     <td>    0.1814</td> <td>    0.006</td> <td>   31.525</td> <td> 0.000</td> <td>    0.170</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98039</th>             <td>    0.1497</td> <td>    0.003</td> <td>   49.436</td> <td> 0.000</td> <td>    0.144</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view_0.0</th>                  <td>   -0.0606</td> <td>    0.004</td> <td>  -15.437</td> <td> 0.000</td> <td>   -0.068</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98112</th>             <td>    0.1396</td> <td>    0.003</td> <td>   43.791</td> <td> 0.000</td> <td>    0.133</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98040</th>             <td>    0.1233</td> <td>    0.003</td> <td>   39.395</td> <td> 0.000</td> <td>    0.117</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98105</th>             <td>    0.0807</td> <td>    0.003</td> <td>   25.486</td> <td> 0.000</td> <td>    0.075</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_3</th>               <td>   -0.0332</td> <td>    0.004</td> <td>   -9.171</td> <td> 0.000</td> <td>   -0.040</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98119</th>             <td>    0.0816</td> <td>    0.003</td> <td>   25.941</td> <td> 0.000</td> <td>    0.075</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view_4.0</th>                  <td>    0.0883</td> <td>    0.004</td> <td>   22.575</td> <td> 0.000</td> <td>    0.081</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98199</th>             <td>    0.0706</td> <td>    0.003</td> <td>   22.180</td> <td> 0.000</td> <td>    0.064</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98109</th>             <td>    0.0644</td> <td>    0.003</td> <td>   20.959</td> <td> 0.000</td> <td>    0.058</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98102</th>             <td>    0.0673</td> <td>    0.003</td> <td>   21.904</td> <td> 0.000</td> <td>    0.061</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98033</th>             <td>    0.0686</td> <td>    0.003</td> <td>   21.498</td> <td> 0.000</td> <td>    0.062</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98103</th>             <td>    0.0702</td> <td>    0.004</td> <td>   20.054</td> <td> 0.000</td> <td>    0.063</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98115</th>             <td>    0.0615</td> <td>    0.003</td> <td>   18.381</td> <td> 0.000</td> <td>    0.055</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98122</th>             <td>    0.0623</td> <td>    0.003</td> <td>   19.546</td> <td> 0.000</td> <td>    0.056</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98117</th>             <td>    0.0538</td> <td>    0.003</td> <td>   15.947</td> <td> 0.000</td> <td>    0.047</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98006</th>             <td>    0.0608</td> <td>    0.003</td> <td>   19.147</td> <td> 0.000</td> <td>    0.055</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98116</th>             <td>    0.0529</td> <td>    0.003</td> <td>   16.893</td> <td> 0.000</td> <td>    0.047</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98107</th>             <td>    0.0510</td> <td>    0.003</td> <td>   15.890</td> <td> 0.000</td> <td>    0.045</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98144</th>             <td>    0.0511</td> <td>    0.003</td> <td>   16.164</td> <td> 0.000</td> <td>    0.045</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_above</th>                <td>    0.2524</td> <td>    0.004</td> <td>   65.591</td> <td> 0.000</td> <td>    0.245</td> <td>    0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_basement</th>             <td>    0.0371</td> <td>    0.004</td> <td>   10.582</td> <td> 0.000</td> <td>    0.030</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors_2.0</th>                <td>   -0.0894</td> <td>    0.005</td> <td>  -19.055</td> <td> 0.000</td> <td>   -0.099</td> <td>   -0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98136</th>             <td>    0.0402</td> <td>    0.003</td> <td>   13.020</td> <td> 0.000</td> <td>    0.034</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors_3.0</th>                <td>   -0.0491</td> <td>    0.004</td> <td>  -13.894</td> <td> 0.000</td> <td>   -0.056</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98005</th>             <td>    0.0387</td> <td>    0.003</td> <td>   12.628</td> <td> 0.000</td> <td>    0.033</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated_(2000, 2010]</th> <td>    0.0367</td> <td>    0.003</td> <td>   12.079</td> <td> 0.000</td> <td>    0.031</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98126</th>             <td>    0.0281</td> <td>    0.003</td> <td>    8.952</td> <td> 0.000</td> <td>    0.022</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms_4</th>                <td>    0.1805</td> <td>    0.030</td> <td>    5.988</td> <td> 0.000</td> <td>    0.121</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98029</th>             <td>    0.0305</td> <td>    0.003</td> <td>    9.878</td> <td> 0.000</td> <td>    0.024</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98118</th>             <td>    0.0267</td> <td>    0.003</td> <td>    8.480</td> <td> 0.000</td> <td>    0.021</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98008</th>             <td>    0.0336</td> <td>    0.003</td> <td>   10.861</td> <td> 0.000</td> <td>    0.028</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view_3.0</th>                  <td>    0.0351</td> <td>    0.003</td> <td>   10.048</td> <td> 0.000</td> <td>    0.028</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_5</th>               <td>    0.0329</td> <td>    0.003</td> <td>    9.917</td> <td> 0.000</td> <td>    0.026</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98027</th>             <td>    0.0248</td> <td>    0.003</td> <td>    8.068</td> <td> 0.000</td> <td>    0.019</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98052</th>             <td>    0.0193</td> <td>    0.003</td> <td>    5.889</td> <td> 0.000</td> <td>    0.013</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms_2</th>                <td>    0.1828</td> <td>    0.022</td> <td>    8.311</td> <td> 0.000</td> <td>    0.140</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98007</th>             <td>    0.0235</td> <td>    0.003</td> <td>    7.704</td> <td> 0.000</td> <td>    0.017</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms_5</th>                <td>    0.0947</td> <td>    0.017</td> <td>    5.572</td> <td> 0.000</td> <td>    0.061</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98019</th>             <td>   -0.0335</td> <td>    0.003</td> <td>  -10.663</td> <td> 0.000</td> <td>   -0.040</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98028</th>             <td>   -0.0323</td> <td>    0.003</td> <td>  -10.100</td> <td> 0.000</td> <td>   -0.039</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms_1</th>                <td>    0.0617</td> <td>    0.007</td> <td>    8.947</td> <td> 0.000</td> <td>    0.048</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms_3</th>                <td>    0.2419</td> <td>    0.032</td> <td>    7.467</td> <td> 0.000</td> <td>    0.178</td> <td>    0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms</th>                 <td>    0.0413</td> <td>    0.005</td> <td>    7.707</td> <td> 0.000</td> <td>    0.031</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98106</th>             <td>    0.0133</td> <td>    0.003</td> <td>    4.288</td> <td> 0.000</td> <td>    0.007</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built_(1930, 1939]</th>     <td>    0.0255</td> <td>    0.003</td> <td>    8.097</td> <td> 0.000</td> <td>    0.019</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built_(1940, 1949]</th>     <td>    0.0263</td> <td>    0.003</td> <td>    7.642</td> <td> 0.000</td> <td>    0.020</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98075</th>             <td>    0.0104</td> <td>    0.003</td> <td>    3.324</td> <td> 0.001</td> <td>    0.004</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98011</th>             <td>   -0.0267</td> <td>    0.003</td> <td>   -8.499</td> <td> 0.000</td> <td>   -0.033</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98155</th>             <td>   -0.0308</td> <td>    0.003</td> <td>   -9.256</td> <td> 0.000</td> <td>   -0.037</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98077</th>             <td>   -0.0268</td> <td>    0.003</td> <td>   -8.426</td> <td> 0.000</td> <td>   -0.033</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot</th>                  <td>    0.0220</td> <td>    0.003</td> <td>    6.767</td> <td> 0.000</td> <td>    0.016</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built_(1920, 1929]</th>     <td>    0.0255</td> <td>    0.004</td> <td>    7.225</td> <td> 0.000</td> <td>    0.019</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built_(2010, 2020]</th>     <td>    0.0161</td> <td>    0.003</td> <td>    5.112</td> <td> 0.000</td> <td>    0.010</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built_(1910, 1919]</th>     <td>    0.0202</td> <td>    0.003</td> <td>    6.049</td> <td> 0.000</td> <td>    0.014</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors_1.5</th>                <td>   -0.0229</td> <td>    0.004</td> <td>   -6.524</td> <td> 0.000</td> <td>   -0.030</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98072</th>             <td>   -0.0210</td> <td>    0.003</td> <td>   -6.554</td> <td> 0.000</td> <td>   -0.027</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98014</th>             <td>   -0.0177</td> <td>    0.003</td> <td>   -5.717</td> <td> 0.000</td> <td>   -0.024</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98133</th>             <td>   -0.0196</td> <td>    0.003</td> <td>   -5.873</td> <td> 0.000</td> <td>   -0.026</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98022</th>             <td>    0.0160</td> <td>    0.003</td> <td>    4.976</td> <td> 0.000</td> <td>    0.010</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98010</th>             <td>    0.0139</td> <td>    0.003</td> <td>    4.598</td> <td> 0.000</td> <td>    0.008</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built_(1970, 1979]</th>     <td>   -0.0161</td> <td>    0.003</td> <td>   -4.852</td> <td> 0.000</td> <td>   -0.023</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98178</th>             <td>   -0.0140</td> <td>    0.003</td> <td>   -4.586</td> <td> 0.000</td> <td>   -0.020</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms_6</th>                <td>    0.0375</td> <td>    0.008</td> <td>    4.902</td> <td> 0.000</td> <td>    0.023</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built_(1900, 1909]</th>     <td>    0.0124</td> <td>    0.003</td> <td>    3.691</td> <td> 0.000</td> <td>    0.006</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98002</th>             <td>    0.0120</td> <td>    0.003</td> <td>    3.903</td> <td> 0.000</td> <td>    0.006</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living15</th>             <td>    0.0219</td> <td>    0.005</td> <td>    4.101</td> <td> 0.000</td> <td>    0.011</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated_(2010, 2020]</th> <td>    0.0116</td> <td>    0.003</td> <td>    3.854</td> <td> 0.000</td> <td>    0.006</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms_8</th>                <td>    0.0100</td> <td>    0.003</td> <td>    2.967</td> <td> 0.003</td> <td>    0.003</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98058</th>             <td>   -0.0090</td> <td>    0.003</td> <td>   -2.962</td> <td> 0.003</td> <td>   -0.015</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98070</th>             <td>   -0.0093</td> <td>    0.003</td> <td>   -3.010</td> <td> 0.003</td> <td>   -0.015</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_98065</th>             <td>   -0.0085</td> <td>    0.003</td> <td>   -2.769</td> <td> 0.006</td> <td>   -0.015</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built_(1960, 1969]</th>     <td>   -0.0089</td> <td>    0.003</td> <td>   -2.598</td> <td> 0.009</td> <td>   -0.016</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>20376.422</td> <th>  Durbin-Watson:     </th>  <td>   1.995</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>4363973.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 4.146</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>72.892</td>   <th>  Cond. No.          </th>  <td>4.58e+15</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.45e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.812\n",
       "Model:                            OLS   Adj. R-squared:                  0.811\n",
       "Method:                 Least Squares   F-statistic:                     1180.\n",
       "Date:                Tue, 07 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        21:01:06   Log-Likelihood:                -12341.\n",
       "No. Observations:               21143   AIC:                         2.484e+04\n",
       "Df Residuals:                   21065   BIC:                         2.546e+04\n",
       "Df Model:                          77                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================\n",
       "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "const                     -1.172e-14      0.003  -3.92e-12      1.000      -0.006       0.006\n",
       "waterfront_1.0                0.1332      0.004     36.163      0.000       0.126       0.140\n",
       "sqft_living                   0.2455      0.004     69.193      0.000       0.239       0.252\n",
       "zipcode_98004                 0.2056      0.003     65.660      0.000       0.200       0.212\n",
       "lat                           0.2086      0.005     44.311      0.000       0.199       0.218\n",
       "grade                         0.1814      0.006     31.525      0.000       0.170       0.193\n",
       "zipcode_98039                 0.1497      0.003     49.436      0.000       0.144       0.156\n",
       "view_0.0                     -0.0606      0.004    -15.437      0.000      -0.068      -0.053\n",
       "zipcode_98112                 0.1396      0.003     43.791      0.000       0.133       0.146\n",
       "zipcode_98040                 0.1233      0.003     39.395      0.000       0.117       0.129\n",
       "zipcode_98105                 0.0807      0.003     25.486      0.000       0.075       0.087\n",
       "condition_3                  -0.0332      0.004     -9.171      0.000      -0.040      -0.026\n",
       "zipcode_98119                 0.0816      0.003     25.941      0.000       0.075       0.088\n",
       "view_4.0                      0.0883      0.004     22.575      0.000       0.081       0.096\n",
       "zipcode_98199                 0.0706      0.003     22.180      0.000       0.064       0.077\n",
       "zipcode_98109                 0.0644      0.003     20.959      0.000       0.058       0.070\n",
       "zipcode_98102                 0.0673      0.003     21.904      0.000       0.061       0.073\n",
       "zipcode_98033                 0.0686      0.003     21.498      0.000       0.062       0.075\n",
       "zipcode_98103                 0.0702      0.004     20.054      0.000       0.063       0.077\n",
       "zipcode_98115                 0.0615      0.003     18.381      0.000       0.055       0.068\n",
       "zipcode_98122                 0.0623      0.003     19.546      0.000       0.056       0.069\n",
       "zipcode_98117                 0.0538      0.003     15.947      0.000       0.047       0.060\n",
       "zipcode_98006                 0.0608      0.003     19.147      0.000       0.055       0.067\n",
       "zipcode_98116                 0.0529      0.003     16.893      0.000       0.047       0.059\n",
       "zipcode_98107                 0.0510      0.003     15.890      0.000       0.045       0.057\n",
       "zipcode_98144                 0.0511      0.003     16.164      0.000       0.045       0.057\n",
       "sqft_above                    0.2524      0.004     65.591      0.000       0.245       0.260\n",
       "sqft_basement                 0.0371      0.004     10.582      0.000       0.030       0.044\n",
       "floors_2.0                   -0.0894      0.005    -19.055      0.000      -0.099      -0.080\n",
       "zipcode_98136                 0.0402      0.003     13.020      0.000       0.034       0.046\n",
       "floors_3.0                   -0.0491      0.004    -13.894      0.000      -0.056      -0.042\n",
       "zipcode_98005                 0.0387      0.003     12.628      0.000       0.033       0.045\n",
       "yr_renovated_(2000, 2010]     0.0367      0.003     12.079      0.000       0.031       0.043\n",
       "zipcode_98126                 0.0281      0.003      8.952      0.000       0.022       0.034\n",
       "bedrooms_4                    0.1805      0.030      5.988      0.000       0.121       0.240\n",
       "zipcode_98029                 0.0305      0.003      9.878      0.000       0.024       0.037\n",
       "zipcode_98118                 0.0267      0.003      8.480      0.000       0.021       0.033\n",
       "zipcode_98008                 0.0336      0.003     10.861      0.000       0.028       0.040\n",
       "view_3.0                      0.0351      0.003     10.048      0.000       0.028       0.042\n",
       "condition_5                   0.0329      0.003      9.917      0.000       0.026       0.039\n",
       "zipcode_98027                 0.0248      0.003      8.068      0.000       0.019       0.031\n",
       "zipcode_98052                 0.0193      0.003      5.889      0.000       0.013       0.026\n",
       "bedrooms_2                    0.1828      0.022      8.311      0.000       0.140       0.226\n",
       "zipcode_98007                 0.0235      0.003      7.704      0.000       0.017       0.029\n",
       "bedrooms_5                    0.0947      0.017      5.572      0.000       0.061       0.128\n",
       "zipcode_98019                -0.0335      0.003    -10.663      0.000      -0.040      -0.027\n",
       "zipcode_98028                -0.0323      0.003    -10.100      0.000      -0.039      -0.026\n",
       "bedrooms_1                    0.0617      0.007      8.947      0.000       0.048       0.075\n",
       "bedrooms_3                    0.2419      0.032      7.467      0.000       0.178       0.305\n",
       "bathrooms                     0.0413      0.005      7.707      0.000       0.031       0.052\n",
       "zipcode_98106                 0.0133      0.003      4.288      0.000       0.007       0.019\n",
       "yr_built_(1930, 1939]         0.0255      0.003      8.097      0.000       0.019       0.032\n",
       "yr_built_(1940, 1949]         0.0263      0.003      7.642      0.000       0.020       0.033\n",
       "zipcode_98075                 0.0104      0.003      3.324      0.001       0.004       0.017\n",
       "zipcode_98011                -0.0267      0.003     -8.499      0.000      -0.033      -0.021\n",
       "zipcode_98155                -0.0308      0.003     -9.256      0.000      -0.037      -0.024\n",
       "zipcode_98077                -0.0268      0.003     -8.426      0.000      -0.033      -0.021\n",
       "sqft_lot                      0.0220      0.003      6.767      0.000       0.016       0.028\n",
       "yr_built_(1920, 1929]         0.0255      0.004      7.225      0.000       0.019       0.032\n",
       "yr_built_(2010, 2020]         0.0161      0.003      5.112      0.000       0.010       0.022\n",
       "yr_built_(1910, 1919]         0.0202      0.003      6.049      0.000       0.014       0.027\n",
       "floors_1.5                   -0.0229      0.004     -6.524      0.000      -0.030      -0.016\n",
       "zipcode_98072                -0.0210      0.003     -6.554      0.000      -0.027      -0.015\n",
       "zipcode_98014                -0.0177      0.003     -5.717      0.000      -0.024      -0.012\n",
       "zipcode_98133                -0.0196      0.003     -5.873      0.000      -0.026      -0.013\n",
       "zipcode_98022                 0.0160      0.003      4.976      0.000       0.010       0.022\n",
       "zipcode_98010                 0.0139      0.003      4.598      0.000       0.008       0.020\n",
       "yr_built_(1970, 1979]        -0.0161      0.003     -4.852      0.000      -0.023      -0.010\n",
       "zipcode_98178                -0.0140      0.003     -4.586      0.000      -0.020      -0.008\n",
       "bedrooms_6                    0.0375      0.008      4.902      0.000       0.023       0.053\n",
       "yr_built_(1900, 1909]         0.0124      0.003      3.691      0.000       0.006       0.019\n",
       "zipcode_98002                 0.0120      0.003      3.903      0.000       0.006       0.018\n",
       "sqft_living15                 0.0219      0.005      4.101      0.000       0.011       0.032\n",
       "yr_renovated_(2010, 2020]     0.0116      0.003      3.854      0.000       0.006       0.018\n",
       "bedrooms_8                    0.0100      0.003      2.967      0.003       0.003       0.017\n",
       "zipcode_98058                -0.0090      0.003     -2.962      0.003      -0.015      -0.003\n",
       "zipcode_98070                -0.0093      0.003     -3.010      0.003      -0.015      -0.003\n",
       "zipcode_98065                -0.0085      0.003     -2.769      0.006      -0.015      -0.002\n",
       "yr_built_(1960, 1969]        -0.0089      0.003     -2.598      0.009      -0.016      -0.002\n",
       "==============================================================================\n",
       "Omnibus:                    20376.422   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4363973.190\n",
       "Skew:                           4.146   Prob(JB):                         0.00\n",
       "Kurtosis:                      72.892   Cond. No.                     4.58e+15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.45e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Used Scikitlearn's Standard Scaler\n",
    "    # Takes each data point, subtracts the mean of the sample, then divides by the standard deviation of the sample\n",
    "\n",
    "ss_scaler = preprocessing.StandardScaler()\n",
    "clean_house_ss = ss_scaler.fit_transform(clean_house)\n",
    "\n",
    "# Standard scaler returns a numpy array, so we converted it back to a DF\n",
    "\n",
    "clean_house_ss = pd.DataFrame(clean_house_ss, columns=list(clean_house.columns))\n",
    "\n",
    "# We generated a list of features to use using a stepwise selection function from Flatiron's learn.co lessons\n",
    "    # Finds the best p values from your features\n",
    "\n",
    "clean_house_selections_list = ['price', 'waterfront_1.0', 'sqft_living', 'zipcode_98004', 'lat', 'grade', 'zipcode_98039', 'view_0.0', 'zipcode_98112', 'zipcode_98040', 'zipcode_98105', 'condition_3', 'zipcode_98119', 'view_4.0', 'zipcode_98199', 'zipcode_98109', 'zipcode_98102', 'zipcode_98033', 'zipcode_98103', 'zipcode_98115', 'zipcode_98122', 'zipcode_98117', 'zipcode_98006', 'zipcode_98116', 'zipcode_98107', 'zipcode_98144', 'sqft_above', 'sqft_basement', 'floors_2.0', 'zipcode_98136', 'floors_3.0', 'zipcode_98005', 'yr_renovated_(2000, 2010]', 'zipcode_98126', 'bedrooms_4', 'zipcode_98029', 'zipcode_98118', 'zipcode_98008', 'view_3.0', 'condition_5', 'zipcode_98027', 'zipcode_98052', 'bedrooms_2', 'zipcode_98007', 'bedrooms_5', 'zipcode_98019', 'zipcode_98028', 'bedrooms_1', 'bedrooms_3', 'bathrooms', 'zipcode_98106', 'yr_built_(1930, 1939]', 'yr_built_(1940, 1949]', 'zipcode_98075', 'zipcode_98011', 'zipcode_98155', 'zipcode_98077', 'sqft_lot', 'yr_built_(1920, 1929]', 'yr_built_(2010, 2020]', 'yr_built_(1910, 1919]', 'floors_1.5', 'zipcode_98072', 'zipcode_98014', 'zipcode_98133', 'zipcode_98022', 'zipcode_98010', 'yr_built_(1970, 1979]', 'zipcode_98178', 'bedrooms_6', 'yr_built_(1900, 1909]', 'zipcode_98002', 'sqft_living15', 'yr_renovated_(2010, 2020]', 'bedrooms_8', 'zipcode_98058', 'zipcode_98070', 'zipcode_98065', 'yr_built_(1960, 1969]']\n",
    "print(len(clean_house_selections_list))\n",
    "\n",
    "# Made a new DF with just the features from our selections list\n",
    "clean_house_selections = clean_house_ss[clean_house_selections_list]\n",
    "\n",
    "# Used statsmodels OLS so we could get a handy summary of the regression results\n",
    "target = clean_house_selections[\"price\"]\n",
    "predictors = clean_house_selections.drop([\"price\"], axis=1)\n",
    "\n",
    "predictors_int = sm.add_constant(predictors)\n",
    "model = sm.OLS(target, predictors_int).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We needed a special train, test, split for our altered data set\n",
    "\n",
    "X1_train,X1_test,y1_train,y1_test=train_test_split(predictors,target,test_size=0.2,random_state=3)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X1_train, y1_train)\n",
    "\n",
    "y_hat_train = linreg.predict(X1_train)\n",
    "y_hat_test = linreg.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squarred Error: 160049.94367147383\n",
      "Test Mean Squarred Error: 156904.21085006962\n"
     ]
    }
   ],
   "source": [
    "# Check the mean squared error\n",
    "\n",
    "mse_train = sqrt(np.sum((y_train-y_hat_train)**2)/len(y_train))\n",
    "mse_test = sqrt(np.sum((y_test-y_hat_test)**2)/len(y_test))\n",
    "print('Train Mean Squarred Error:', mse_train)\n",
    "print('Test Mean Squarred Error:', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation scores\n",
    "    # Took the mean cv score because cross_val_score returns a score for each fold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results = np.mean(cross_val_score(linreg, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_10_results = np.mean(cross_val_score(linreg, X, y, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "cv_20_results = np.mean(cross_val_score(linreg, X, y, cv=20, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-36000388037.17259\n",
      "-3460842866955.49\n",
      "-126057102063.8781\n"
     ]
    }
   ],
   "source": [
    "print(cv_5_results)\n",
    "print(cv_10_results)\n",
    "print(cv_20_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression 2: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "    # Lasso helps prevent overfitting by reducing the influence of some of the predictors by penalizing their coefficients or reducing them to zero (effectively doing predictor selection)\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the training/test scores (R2) of our model \n",
    "\n",
    "train_score=lasso.score(X_train,y_train)\n",
    "test_score=lasso.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.8136391869874172\n",
      "test score:  0.8069445302396594\n"
     ]
    }
   ],
   "source": [
    "print(\"training score:\", train_score)\n",
    "print(\"test score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features used: 129\n",
      "number eliminated: 6\n"
     ]
    }
   ],
   "source": [
    "# Checking to see how many features were used and how many were axed\n",
    "\n",
    "coeff_used = np.sum(lasso.coef_!=0)\n",
    "print(\"number of features used:\", coeff_used)\n",
    "print(\"number eliminated:\", len(list(clean_house.columns)) - coeff_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squarred Error: 160093.67514929673\n",
      "Test Root Mean Squarred Error: 157035.18141621255\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "y_hat_train = lasso.predict(X_train)\n",
    "y_hat_test = lasso.predict(X_test)\n",
    "\n",
    "mse_train = sqrt(np.sum((y_train-y_hat_train)**2)/len(y_train))\n",
    "mse_test = sqrt(np.sum((y_test-y_hat_test)**2)/len(y_test))\n",
    "print('Train Root Mean Squarred Error:', mse_train)\n",
    "print('Test Root Mean Squarred Error:', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "\n",
    "cv_5_results = np.mean(cross_val_score(lasso, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_10_results = np.mean(cross_val_score(lasso, X, y, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "cv_20_results = np.mean(cross_val_score(lasso, X, y, cv=20, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-26199746025.946964\n",
      "-26113016000.716778\n",
      "-25954632087.912758\n"
     ]
    }
   ],
   "source": [
    "print(cv_5_results)\n",
    "print(cv_10_results)\n",
    "print(cv_20_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression 3: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An important difference between Lasso and Ridge is that Ridge doesn't reduce any features' coefficient to 0 (though they can get very, very small)\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the scores\n",
    "\n",
    "rtrain_score=ridge.score(X_train,y_train)\n",
    "rtest_score=ridge.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.8136008450949628\n",
      "test score:  0.80715057788118\n"
     ]
    }
   ],
   "source": [
    "print(\"training score:\", rtrain_score)\n",
    "print(\"test score: \", rtest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squarred Error: 160049.94367147383\n",
      "Test Root Mean Squarred Error: 156904.21085006962\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "\n",
    "y_hat_train = ridge.predict(X_train)\n",
    "y_hat_test = ridge.predict(X_test)\n",
    "\n",
    "mse_train = sqrt(np.sum((y_train-y_hat_train)**2)/len(y_train))\n",
    "mse_test = sqrt(np.sum((y_test-y_hat_test)**2)/len(y_test))\n",
    "print('Train Root Mean Squarred Error:', mse_train)\n",
    "print('Test Root Mean Squarred Error:', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "\n",
    "cv_5_results = np.mean(cross_val_score(ridge, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_10_results = np.mean(cross_val_score(ridge, X, y, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "cv_20_results = np.mean(cross_val_score(ridge, X, y, cv=20, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-26192705525.218136\n",
      "-26113909169.27703\n",
      "-25955490873.20748\n"
     ]
    }
   ],
   "source": [
    "print(cv_5_results)\n",
    "print(cv_10_results)\n",
    "print(cv_20_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Gridsearch for best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'alpha': [0.001, 0.01, 1, 5, 10, 20, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 20}\n",
      "Best score: -26113231427.35375\n"
     ]
    }
   ],
   "source": [
    "lasso_regressor = GridSearchCV(lasso, param, scoring='neg_mean_squared_error', cv=10)\n",
    "lasso_regressor.fit(X, y)\n",
    "\n",
    "print('Best parameters:', lasso_regressor.best_params_)\n",
    "print('Best score:', lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=20, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha = 20)\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score=lasso.score(X_train,y_train)\n",
    "test_score=lasso.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.8134989690934248\n",
      "test score:  0.8068284942439361\n"
     ]
    }
   ],
   "source": [
    "print(\"training score:\", train_score)\n",
    "print(\"test score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features used: 123\n",
      "number eliminated: 12\n"
     ]
    }
   ],
   "source": [
    "coeff_used = np.sum(lasso.coef_!=0)\n",
    "print(\"number of features used:\", coeff_used)\n",
    "print(\"number eliminated:\", len(list(clean_house.columns)) - coeff_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squarred Error: 160093.67514929673\n",
      "Test Mean Squarred Error: 157035.18141621255\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "y_hat_train = lasso.predict(X_train)\n",
    "y_hat_test = lasso.predict(X_test)\n",
    "\n",
    "mse_train = sqrt(np.sum((y_train-y_hat_train)**2)/len(y_train))\n",
    "mse_test = sqrt(np.sum((y_test-y_hat_test)**2)/len(y_test))\n",
    "print('Train Mean Squarred Error:', mse_train)\n",
    "print('Test Mean Squarred Error:', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "\n",
    "cv_5_results = np.mean(cross_val_score(lasso, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_10_results = np.mean(cross_val_score(lasso, X, y, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "cv_20_results = np.mean(cross_val_score(lasso, X, y, cv=20, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-26192705525.218136\n",
      "-26113909169.27703\n",
      "-25955490873.20748\n"
     ]
    }
   ],
   "source": [
    "print(cv_5_results)\n",
    "print(cv_10_results)\n",
    "print(cv_20_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-1d4d9e2bce5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m         verts=verts, edgecolors=edgecolors, **({\"data\": data} if data\n\u001b[0;32m-> 2862\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2863\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4180\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test, y_test,  color='green')\n",
    "plt.plot(X_test, y_hat_test, color='blue', linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5103      692500.0\n",
       "12331     339900.0\n",
       "18395     685000.0\n",
       "4955     1000000.0\n",
       "11009     315000.0\n",
       "11743     250000.0\n",
       "19263     458000.0\n",
       "711       243000.0\n",
       "20858     775000.0\n",
       "4678      690000.0\n",
       "5944      320000.0\n",
       "4325      227000.0\n",
       "18113     765000.0\n",
       "21194     500000.0\n",
       "17981    1990000.0\n",
       "5559      258000.0\n",
       "756       942500.0\n",
       "10955     282000.0\n",
       "3416      375000.0\n",
       "864       280000.0\n",
       "2052      297000.0\n",
       "12371     164000.0\n",
       "16551     385000.0\n",
       "8355      782000.0\n",
       "9275      265000.0\n",
       "12572     648000.0\n",
       "6873      327500.0\n",
       "7855      330000.0\n",
       "2962      999000.0\n",
       "6467      503500.0\n",
       "           ...    \n",
       "10341     401000.0\n",
       "20364     500000.0\n",
       "552       451000.0\n",
       "6685     2000000.0\n",
       "8020      480000.0\n",
       "14979     152500.0\n",
       "20427     385000.0\n",
       "6494      755000.0\n",
       "18812     732000.0\n",
       "249       481000.0\n",
       "5033      195000.0\n",
       "18314    2920000.0\n",
       "2258      208000.0\n",
       "7934      450000.0\n",
       "14022     550000.0\n",
       "185      1100000.0\n",
       "3180      440000.0\n",
       "8504      355000.0\n",
       "12293     583000.0\n",
       "6305      367500.0\n",
       "2883      402000.0\n",
       "7439      277000.0\n",
       "16544     350000.0\n",
       "13872     475000.0\n",
       "11627     420000.0\n",
       "5674      529900.0\n",
       "10401     525000.0\n",
       "8911      214000.0\n",
       "15599     227000.0\n",
       "13901     335000.0\n",
       "Name: price, Length: 4229, dtype: float64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
